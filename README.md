# ğŸ¤– local-agent

Build your own **fully local AI agents** using Python â€” no API keys, no cloud fees.

This project demonstrates how to set up and run local language model agents using:

- ğŸ§  [Ollama](https://ollama.ai/) â€“ Run large language models locally (e.g. LLaMA, Mistral)
- ğŸ”— [LangChain](https://github.com/langchain-ai/langchain) â€“ Framework for building agent workflows
- ğŸ“š [ChromaDB](https://www.trychroma.com/) â€“ Lightweight local vector store for RAG (retrieval augmented generation)

All components are 100% offline and **free to use locally**.

---

## ğŸš€ Features

- ğŸ”§ Fully local agent execution using Ollama
- ğŸ” Document embedding and semantic search with ChromaDB
- ğŸ§© Modular agent logic via LangChain
- ğŸ› ï¸ Designed for extensibility (tools, memory, RAG, etc.)

---

## ğŸ“¦ Requirements

- Python 3.10+
- [Ollama](https://ollama.ai/)
- pip packages:
  ```bash
  pip install -r requirements.txt
  ```

---

## ğŸ§ª Quick Start

```bash
# 1. Run an Ollama model
ollama run mistral

# 2. Start your local agent
python agent.py
```

> You can switch models like `llama2`, `mistral`, or `codellama` by changing the agent config.

---

## ğŸ“ Project Structure

```bash
local-agent/
â”œâ”€â”€ agent.py           # Main agent logic
â”œâ”€â”€ vector_store.py    # ChromaDB setup and retrieval
â”œâ”€â”€ tools/             # Optional agent tools
â”œâ”€â”€ docs/              # Embedded documents for search
â””â”€â”€ README.md
```

---

## ğŸ§  Coming Soon

- Memory-enhanced agents
- Custom toolchains
- Agent CLI / Web UI

---

## ğŸ“ License

This project is open source under the [MIT License](LICENSE).

```

---
```
